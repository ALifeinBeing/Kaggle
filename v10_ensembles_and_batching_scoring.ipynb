{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as skm\n",
    "import time\n",
    "import operator\n",
    "import re\n",
    "from sklearn.utils import resample\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import grid_search\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> FUNCTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> GET DATA AND DEFINE TEST/TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\".\\\\train.csv\",parse_dates=[0])\n",
    "train[\"key\"] = 'Train'\n",
    "test = pd.read_csv(\".\\\\test.csv\",parse_dates=[1])\n",
    "test[\"key\"] = 'Test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.concat([train,test])\n",
    "df.reset_index(inplace=True)\n",
    "df.drop('index',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dat = pd.DataFrame(df[\"Dates\"])\n",
    "dat = dat.drop_duplicates()\n",
    "dat.reset_index(inplace=True)\n",
    "del dat[\"index\"]\n",
    "dat[\"linear_time\"] = dat.index\n",
    "df = df.merge(dat,how='left', left_on='Dates',right_on='Dates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kane.Merrill\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:117: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "df[\"New_Cat\"] = \"NON TOP FOUR\"\n",
    "df[\"New_Cat\"].ix[df[\"Category\"] ==\"OTHER OFFENSES\"] = \"OTHER OFFENSES\"\n",
    "df[\"New_Cat\"].ix[df[\"Category\"] ==\"LARCENY/THEFT\"] = \"LARCENY/THEFT\"\n",
    "df[\"New_Cat\"].ix[df[\"Category\"] ==\"NON-CRIMINAL\"] = \"NON-CRIMINAL\"\n",
    "df[\"New_Cat\"].ix[df[\"Category\"] ==\"ASSAULT\"] = \"ASSAULT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68.50351977348328\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "df[\"hour\"] = df.Dates.apply(lambda x: x.hour)\n",
    "df[\"month\"] = df.Dates.apply(lambda x: x.month)\n",
    "df[\"week\"] = df.Dates.apply(lambda x: x.week)\n",
    "df[\"year\"] = df.Dates.apply(lambda x: x.year)\n",
    "df[\"day\"] = df.Dates.apply(lambda x: x.day)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[\"weekday\"] = df.Dates.apply(lambda x: x.weekday)\n",
    "df[\"weekofyear\"] = df.Dates.apply(lambda x: x.weekofyear)\n",
    "df[\"dayofyear\"] = df.Dates.apply(lambda x: x.dayofyear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dow = {\n",
    "'Monday':0,\n",
    "'Tuesday':1,\n",
    "'Wednesday':2,\n",
    "'Thursday':3,\n",
    "'Friday':4,\n",
    "'Saturday':5,\n",
    "'Sunday':6\n",
    "}\n",
    "df[\"DOW\"] = df.DayOfWeek.map(dow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"X_shift_small\"] = df[\"X\"].apply(lambda x: x * 10).astype(int)\n",
    "df[\"Y_shift_small\"] = df[\"Y\"].apply(lambda x: x * 10).astype(int)\n",
    "\n",
    "df[\"X_shift\"] = df[\"X\"].apply(lambda x: x * 100).astype(int)\n",
    "df[\"Y_shift\"] = df[\"Y\"].apply(lambda x: x * 100).astype(int)\n",
    "\n",
    "df[\"X_shift_big\"] = df[\"X\"].apply(lambda x: (x * 1000)/7).astype(int)\n",
    "df[\"Y_shift_big\"] = df[\"Y\"].apply(lambda x: (x * 1000)/7).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def TOD(x):\n",
    "    if x in range(8,21):\n",
    "        return \"Day\"\n",
    "    else:\n",
    "        return \"Night\"\n",
    "df[\"TOD\"] = df.hour.map(TOD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xy_scaler=preprocessing.StandardScaler()\n",
    "xy_scaler.fit(df[[\"X\",\"Y\"]])\n",
    "df[\"X_fit\"] = df[\"X\"]\n",
    "df[\"Y_fit\"] = df[\"Y\"]\n",
    "df[[\"X_fit\",\"Y_fit\"]]=xy_scaler.transform(df[[\"X\",\"Y\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"rot45_X\"] = .707* df[\"Y_fit\"] + .707* df[\"X_fit\"] \n",
    "df[\"rot45_Y\"] = .707* df[\"Y_fit\"] - .707* df[\"X_fit\"]\n",
    "\n",
    "df[\"rot30_X\"] = (1.732/2)* df[\"X_fit\"] + (1./2)* df[\"Y_fit\"] \n",
    "df[\"rot30_Y\"] = (1.732/2)* df[\"Y_fit\"] - (1./2)* df[\"X_fit\"]\n",
    "\n",
    "df[\"rot60_X\"] = (1./2)* df[\"X_fit\"] + (1.732/2)* df[\"Y_fit\"] \n",
    "df[\"rot60_Y\"] = (1./2)* df[\"Y_fit\"] - (1.732/2)* df[\"X_fit\"]\n",
    "\n",
    "df[\"radial_r\"] = np.sqrt( np.power(df[\"Y_fit\"],2) + np.power(df[\"X_fit\"],2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"X_shift_big_rot\"] = df[\"rot30_X\"].apply(lambda x: (x * 10)).astype(int)\n",
    "df[\"Y_shift_big_rot\"] = df[\"rot30_Y\"].apply(lambda x: (x * 10)).astype(int)\n",
    "df[\"rad\"] = df[\"radial_r\"].apply(lambda x: x * 10).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def address(x):\n",
    "    if re.search(\"/\",x) == None:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"Corner\"] = df[\"Address\"].map(address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def street_one(x):\n",
    "    return x.split()[-2]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def street_two(x):\n",
    "    return x.split()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_number(x):\n",
    "    return x.split()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"Street_One\"] = 0\n",
    "df[\"Street_Two\"] = 0\n",
    "df[\"Address_Number\"] = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kane.Merrill\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:117: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "df[\"Street_One\"] = df[\"Address\"].map(street_one)\n",
    "df[\"Street_Two\"].loc[(df[\"Corner\"]==1)] = df[\"Address\"].map(street_two)\n",
    "df[\"Address_Number\"].loc[(df[\"Corner\"]==0)]= df[\"Address\"].map(add_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"PD_factor\"] = pd.factorize(df[\"PdDistrict\"])[0]\n",
    "df[\"Address_factor\"] = pd.factorize(df[\"Address\"])[0]\n",
    "df[\"Street_One\"] = pd.factorize(df[\"Street_One\"])[0]\n",
    "df[\"Street_Two\"] = pd.factorize(df[\"Street_Two\"])[0]\n",
    "df[\"Address_Number\"] = pd.factorize(df[\"Address_Number\"])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> TESTING FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "origtrainmask = df['key'] == 'Train'\n",
    "origtestmask = df['key'] == 'Test'\n",
    "origtraindf = df[origtrainmask]\n",
    "origtestdf = df[origtestmask]\n",
    "#origtestdf.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mod = RandomForestClassifier(n_estimators=100,min_samples_leaf=25,max_depth=15\\\n",
    "                             ,n_jobs=-1,warm_start=True)\n",
    "mod.fit(origtraindf[[\"Address_Number\",\"Street_One\",\"Street_Two\",\"X_fit\",\"Y_fit\",\"rad\",\"DOW\",\"year\",\\\n",
    "\"hour\",\"PD_factor\"]].as_matrix(),origtraindf[[\"Category\"]].as_matrix().ravel())\n",
    "x = pd.DataFrame()\n",
    "origtestdf.reset_index(inplace=True,drop=True)\n",
    "rounds = np.ceil(((origtestdf.index.max()+1)/25000))\n",
    "for i in range(int(rounds)):\n",
    "    minn = i * 25000\n",
    "    maxx = 25000 + minn\n",
    "    a = pd.DataFrame(mod.predict_proba(origtestdf[[\"Address_Number\",\"Street_One\",\"Street_Two\",\"X_fit\",\"Y_fit\",\"rad\",\"DOW\",\"year\",\\\n",
    "\"hour\",\"PD_factor\"]].loc[(origtestdf.index>=minn) & (origtestdf.index<maxx)]))\n",
    "    x = x.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mod2 = RandomForestClassifier(n_estimators=100,min_samples_leaf=25,max_depth=15\\\n",
    "                             ,n_jobs=-1,warm_start=True)\n",
    "mod2.fit(origtraindf[[\"X_fit\",\"Y_fit\",\"rad\",\"year\",\\\n",
    "\"hour\",\"PD_factor\"]].as_matrix(),origtraindf[[\"Category\"]].as_matrix().ravel())\n",
    "\n",
    "x2 = pd.DataFrame()\n",
    "rounds = np.ceil(((origtestdf.index.max()+1)/25000))\n",
    "for i in range(int(rounds)):\n",
    "    minn = i * 25000\n",
    "    maxx = 25000 + minn\n",
    "    a = pd.DataFrame(mod2.predict_proba(origtestdf[[\"X_fit\",\"Y_fit\",\"rad\",\"year\",\\\n",
    "\"hour\",\"PD_factor\"]].loc[(origtestdf.index>=minn) & (origtestdf.index<maxx)]))\n",
    "    x2 = x2.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mod3 = RandomForestClassifier(n_estimators=100,min_samples_leaf=25,max_depth=15\\\n",
    "                             ,n_jobs=-1,warm_start=True)\n",
    "mod3.fit(origtraindf[[\"Corner\",\"Address_factor\",\"X_fit\",\"Y_fit\",\"year\",\\\n",
    "\"hour\",\"PD_factor\"]].as_matrix(),origtraindf[[\"Category\"]].as_matrix().ravel())\n",
    "x3 = pd.DataFrame()\n",
    "rounds = np.ceil(((origtestdf.index.max()+1)/25000))\n",
    "for i in range(int(rounds)):\n",
    "    minn = i * 25000\n",
    "    maxx = 25000 + minn\n",
    "    a = pd.DataFrame(mod3.predict_proba(origtestdf[[\"Corner\",\"Address_factor\",\"X_fit\",\"Y_fit\",\"year\",\\\n",
    "\"hour\",\"PD_factor\"]].loc[(origtestdf.index>=minn) & (origtestdf.index<maxx)]))\n",
    "    x3 = x3.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wx = x * .6\n",
    "wx2 = x2 * .2\n",
    "wx3 = x3 * .2\n",
    "\n",
    "y = wx + wx2 + wx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y.reset_index(inplace=True,drop=True)\n",
    "y.columns = mod.classes_\n",
    "y = y.merge(origtestdf[[\"Id\"]],how='left',left_index=True,right_index=True)\n",
    "y = y.fillna(0)\n",
    "y[\"Id\"] = y[\"Id\"].astype(int)\n",
    "y[\"Id\"] = y[\"Id\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in y.columns:\n",
    "    if col != \"Id\":\n",
    "        y[col] = y[col].round(decimals=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARSON</th>\n",
       "      <th>ASSAULT</th>\n",
       "      <th>BAD CHECKS</th>\n",
       "      <th>BRIBERY</th>\n",
       "      <th>BURGLARY</th>\n",
       "      <th>DISORDERLY CONDUCT</th>\n",
       "      <th>DRIVING UNDER THE INFLUENCE</th>\n",
       "      <th>DRUG/NARCOTIC</th>\n",
       "      <th>DRUNKENNESS</th>\n",
       "      <th>EMBEZZLEMENT</th>\n",
       "      <th>...</th>\n",
       "      <th>STOLEN PROPERTY</th>\n",
       "      <th>SUICIDE</th>\n",
       "      <th>SUSPICIOUS OCC</th>\n",
       "      <th>TREA</th>\n",
       "      <th>TRESPASS</th>\n",
       "      <th>VANDALISM</th>\n",
       "      <th>VEHICLE THEFT</th>\n",
       "      <th>WARRANTS</th>\n",
       "      <th>WEAPON LAWS</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004052</td>\n",
       "      <td>0.132886</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.001043</td>\n",
       "      <td>0.037646</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>0.003572</td>\n",
       "      <td>0.023707</td>\n",
       "      <td>0.001870</td>\n",
       "      <td>0.001371</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005565</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.054528</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.006325</td>\n",
       "      <td>0.079582</td>\n",
       "      <td>0.127304</td>\n",
       "      <td>0.026018</td>\n",
       "      <td>0.019444</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.083574</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.002773</td>\n",
       "      <td>0.002664</td>\n",
       "      <td>0.009085</td>\n",
       "      <td>0.063781</td>\n",
       "      <td>0.003140</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001639</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>0.036070</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001558</td>\n",
       "      <td>0.016911</td>\n",
       "      <td>0.053405</td>\n",
       "      <td>0.088856</td>\n",
       "      <td>0.027568</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.005087</td>\n",
       "      <td>0.059420</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.100746</td>\n",
       "      <td>0.000992</td>\n",
       "      <td>0.001073</td>\n",
       "      <td>0.017090</td>\n",
       "      <td>0.003163</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006514</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.027880</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007708</td>\n",
       "      <td>0.060943</td>\n",
       "      <td>0.070925</td>\n",
       "      <td>0.018652</td>\n",
       "      <td>0.002757</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000704</td>\n",
       "      <td>0.130627</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.001466</td>\n",
       "      <td>0.033928</td>\n",
       "      <td>0.003759</td>\n",
       "      <td>0.002234</td>\n",
       "      <td>0.055586</td>\n",
       "      <td>0.008239</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013286</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.042843</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004329</td>\n",
       "      <td>0.076780</td>\n",
       "      <td>0.083437</td>\n",
       "      <td>0.059459</td>\n",
       "      <td>0.019407</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000704</td>\n",
       "      <td>0.130627</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.001466</td>\n",
       "      <td>0.033928</td>\n",
       "      <td>0.003759</td>\n",
       "      <td>0.002234</td>\n",
       "      <td>0.055586</td>\n",
       "      <td>0.008239</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013286</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.042843</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004329</td>\n",
       "      <td>0.076780</td>\n",
       "      <td>0.083437</td>\n",
       "      <td>0.059459</td>\n",
       "      <td>0.019407</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ARSON   ASSAULT  BAD CHECKS   BRIBERY  BURGLARY  DISORDERLY CONDUCT  \\\n",
       "0  0.004052  0.132886    0.000123  0.001043  0.037646            0.001860   \n",
       "1  0.000537  0.083574    0.000015  0.000184  0.002773            0.002664   \n",
       "2  0.005087  0.059420    0.000276  0.000017  0.100746            0.000992   \n",
       "3  0.000704  0.130627    0.000076  0.001466  0.033928            0.003759   \n",
       "4  0.000704  0.130627    0.000076  0.001466  0.033928            0.003759   \n",
       "\n",
       "   DRIVING UNDER THE INFLUENCE  DRUG/NARCOTIC  DRUNKENNESS  EMBEZZLEMENT ...  \\\n",
       "0                     0.003572       0.023707     0.001870      0.001371 ...   \n",
       "1                     0.009085       0.063781     0.003140      0.000298 ...   \n",
       "2                     0.001073       0.017090     0.003163      0.000261 ...   \n",
       "3                     0.002234       0.055586     0.008239      0.000110 ...   \n",
       "4                     0.002234       0.055586     0.008239      0.000110 ...   \n",
       "\n",
       "   STOLEN PROPERTY   SUICIDE  SUSPICIOUS OCC      TREA  TRESPASS  VANDALISM  \\\n",
       "0         0.005565  0.000299        0.054528  0.000001  0.006325   0.079582   \n",
       "1         0.001639  0.000330        0.036070  0.000000  0.001558   0.016911   \n",
       "2         0.006514  0.000189        0.027880  0.000000  0.007708   0.060943   \n",
       "3         0.013286  0.000207        0.042843  0.000000  0.004329   0.076780   \n",
       "4         0.013286  0.000207        0.042843  0.000000  0.004329   0.076780   \n",
       "\n",
       "   VEHICLE THEFT  WARRANTS  WEAPON LAWS  Id  \n",
       "0       0.127304  0.026018     0.019444   0  \n",
       "1       0.053405  0.088856     0.027568   1  \n",
       "2       0.070925  0.018652     0.002757   2  \n",
       "3       0.083437  0.059459     0.019407   3  \n",
       "4       0.083437  0.059459     0.019407   4  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y.to_csv(\".\\\\Fourteenth_RF_combo_of_three_RF.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=15, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=25, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
       "            oob_score=True, random_state=None, verbose=0, warm_start=True)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(\\\n",
    "origtraindf[[\"Address_Number\",\"Street_One\",\"Street_Two\",\"X_fit\",\"Y_fit\",\"rad\",\"DOW\",\"year\",\\\n",
    "\"hour\",\"PD_factor\"]],origtraindf[[\"Category\"]],\\\n",
    "        test_size = .2, random_state=25)\n",
    "\n",
    "mod = RandomForestClassifier(n_estimators=100,min_samples_leaf=25,max_depth=15\\\n",
    "                             ,n_jobs=-1,warm_start=True,oob_score = True)\n",
    "mod.fit(origtraindf[[\"Address_Number\",\"Street_One\",\"Street_Two\",\"X_fit\",\"Y_fit\",\"rad\",\"DOW\",\"year\",\\\n",
    "\"hour\",\"PD_factor\"]].as_matrix(),origtraindf[[\"Category\"]].as_matrix().ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = pd.DataFrame()\n",
    "origtestdf.reset_index(inplace=True,drop=True)\n",
    "rounds = np.ceil(((origtestdf.index.max()+1)/25000))\n",
    "for i in range(int(rounds)):\n",
    "    minn = i * 25000\n",
    "    maxx = 25000 + minn\n",
    "    a = pd.DataFrame(mod.predict_proba(origtestdf[[\"Address_Number\",\"Street_One\",\"Street_Two\",\"X_fit\",\"Y_fit\",\"rad\",\"DOW\",\"year\",\\\n",
    "\"hour\",\"PD_factor\"]].loc[(origtestdf.index>=minn) & (origtestdf.index<maxx)]))\n",
    "    x = x.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3292350922796241"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skm.log_loss(pd.get_dummies(Y_test),x.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=15, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=25, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
       "            oob_score=True, random_state=None, verbose=0, warm_start=True)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(\\\n",
    "origtraindf[[\"X_fit\",\"Y_fit\",\"rad\",\"year\",\\\n",
    "\"hour\",\"PD_factor\"]],origtraindf[[\"Category\"]],\\\n",
    "        test_size = .2, random_state=25)\n",
    "\n",
    "mod2 = RandomForestClassifier(n_estimators=100,min_samples_leaf=25,max_depth=15\\\n",
    "                             ,n_jobs=-1,warm_start=True,oob_score = True)\n",
    "mod2.fit(origtraindf[[\"X_fit\",\"Y_fit\",\"rad\",\"year\",\\\n",
    "\"hour\",\"PD_factor\"]].as_matrix(),origtraindf[[\"Category\"]].as_matrix().ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x2 = pd.DataFrame()\n",
    "X_test.reset_index(inplace=True,drop=True)\n",
    "rounds = np.ceil(((origtestdf.index.max()+1)/25000))\n",
    "for i in range(int(rounds)):\n",
    "    minn = i * 25000\n",
    "    maxx = 25000 + minn\n",
    "    a = pd.DataFrame(mod2.predict_proba(origtestdf[[\"X_fit\",\"Y_fit\",\"rad\",\"year\",\\\n",
    "\"hour\",\"PD_factor\"]].loc[(origtestdf.index>=minn) & (origtestdf.index<maxx)]))\n",
    "    x2 = x2.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3713926496101774"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skm.log_loss(pd.get_dummies(Y_test),x2.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=15, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=25, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
       "            oob_score=True, random_state=None, verbose=0, warm_start=True)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(origtraindf[[\"Corner\",\"Address_factor\",\"X_fit\",\"Y_fit\",\"year\",\\\n",
    "\"hour\",\"PD_factor\"]],origtraindf[[\"Category\"]],test_size = .2, random_state=25)\n",
    "\n",
    "mod3 = RandomForestClassifier(n_estimators=100,min_samples_leaf=25,max_depth=15\\\n",
    "                             ,n_jobs=-1,warm_start=True,oob_score = True)\n",
    "mod3.fit(origtraindf[[\"Corner\",\"Address_factor\",\"X_fit\",\"Y_fit\",\"year\",\\\n",
    "\"hour\",\"PD_factor\"]],origtraindf[[\"Category\"]].as_matrix().ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x3 = pd.DataFrame()\n",
    "X_test.reset_index(inplace=True,drop=True)\n",
    "rounds = np.ceil(((origtestdf.index.max()+1)/25000))\n",
    "for i in range(int(rounds)):\n",
    "    minn = i * 25000\n",
    "    maxx = 25000 + minn\n",
    "    a = pd.DataFrame(mod3.predict_proba(origtestdf[[\"Corner\",\"Address_factor\",\"X_fit\",\"Y_fit\",\"year\",\\\n",
    "\"hour\",\"PD_factor\"]].loc[(origtestdf.index>=minn) & (origtestdf.index<maxx)]))\n",
    "    x3 = x3.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3369653311294658"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skm.log_loss(pd.get_dummies(Y_test),x3.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=15, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=25, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
       "            oob_score=True, random_state=None, verbose=0, warm_start=True)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(origtraindf[[\"Address_factor\",\"X_fit\",\"Y_fit\",\"year\",\\\n",
    "\"hour\"]],origtraindf[[\"Category\"]],test_size = .2, random_state=25)\n",
    "\n",
    "mod4 = RandomForestClassifier(n_estimators=100,min_samples_leaf=25,max_depth=15\\\n",
    "                             ,n_jobs=-1,warm_start=True,oob_score = True)\n",
    "mod4.fit(origtraindf[[\"Address_factor\",\"X_fit\",\"Y_fit\",\"year\",\\\n",
    "\"hour\"]],origtraindf[[\"Category\"]].as_matrix().ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x4 = pd.DataFrame()\n",
    "X_test.reset_index(inplace=True,drop=True)\n",
    "rounds = np.ceil(((origtestdf.index.max()+1)/25000))\n",
    "for i in range(int(rounds)):\n",
    "    minn = i * 25000\n",
    "    maxx = 25000 + minn\n",
    "    a = pd.DataFrame(mod4.predict_proba(origtestdf[[\"Address_factor\",\"X_fit\",\"Y_fit\",\"year\",\\\n",
    "\"hour\"]].loc[(origtestdf.index>=minn) & (origtestdf.index<maxx)]))\n",
    "    x4 = x4.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3628714744073704"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skm.log_loss(pd.get_dummies(Y_test),x4.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=15, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=25, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
       "            oob_score=True, random_state=None, verbose=0, warm_start=True)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(origtraindf[[\"Corner\",\"Address_factor\",\"X_fit\",\"Y_fit\",\"year\"]]\\\n",
    "                                                    ,origtraindf[[\"Category\"]],test_size = .2, random_state=25)\n",
    "\n",
    "mod5 = RandomForestClassifier(n_estimators=100,min_samples_leaf=25,max_depth=15\\\n",
    "                             ,n_jobs=-1,warm_start=True,oob_score = True)\n",
    "mod5.fit(origtraindf[[\"Corner\",\"Address_factor\",\"X_fit\",\"Y_fit\",\"year\"]],origtraindf[[\"Category\"]].as_matrix().ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x5 = pd.DataFrame()\n",
    "X_test.reset_index(inplace=True,drop=True)\n",
    "rounds = np.ceil(((origtestdf.index.max()+1)/25000))\n",
    "for i in range(int(rounds)):\n",
    "    minn = i * 25000\n",
    "    maxx = 25000 + minn\n",
    "    a = pd.DataFrame(mod5.predict_proba(origtestdf[[\"Corner\",\"Address_factor\",\"X_fit\",\"Y_fit\",\"year\"]].loc[(origtestdf.index>=minn) & (origtestdf.index<maxx)]))\n",
    "    x5 = x5.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=15, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=25, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
       "            oob_score=True, random_state=None, verbose=0, warm_start=True)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(origtraindf[[\"Street_One\",\"Street_Two\",\"Address_Number\",\"X_fit\",\"Y_fit\",\"year\"]]\\\n",
    "                                                    ,origtraindf[[\"Category\"]],test_size = .2, random_state=25)\n",
    "\n",
    "mod6 = RandomForestClassifier(n_estimators=100,min_samples_leaf=25,max_depth=15\\\n",
    "                             ,n_jobs=-1,warm_start=True,oob_score = True)\n",
    "mod6.fit(origtraindf[[\"Street_One\",\"Street_Two\",\"Address_Number\",\"X_fit\",\"Y_fit\",\"year\"]],origtraindf[[\"Category\"]].as_matrix().ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x6 = pd.DataFrame()\n",
    "X_test.reset_index(inplace=True,drop=True)\n",
    "rounds = np.ceil(((origtestdf.index.max()+1)/25000))\n",
    "for i in range(int(rounds)):\n",
    "    minn = i * 25000\n",
    "    maxx = 25000 + minn\n",
    "    a = pd.DataFrame(mod6.predict_proba(origtestdf[[\"Street_One\",\"Street_Two\",\"Address_Number\",\"X_fit\",\"Y_fit\",\"year\"]].loc[(origtestdf.index>=minn) & (origtestdf.index<maxx)]))\n",
    "    x6 = x6.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_score = mod.oob_score_ + mod2.oob_score_ + mod3.oob_score_ + mod4.oob_score_\\\n",
    "+ mod5.oob_score_ + mod6.oob_score_\n",
    "\n",
    "wx = x * (mod.oob_score_/total_score)\n",
    "wx2 = x2 * (mod2.oob_score_/total_score)\n",
    "wx3 = x3 * (mod3.oob_score_/total_score)\n",
    "wx4 = x4 * (mod4.oob_score_/total_score)\n",
    "wx5 = x5 * (mod5.oob_score_/total_score)\n",
    "wx6 = x6 * (mod6.oob_score_/total_score)\n",
    "\n",
    "y = wx + wx2 + wx3 + wx4 + wx5 + wx6\n",
    "\n",
    "#skm.log_loss(pd.get_dummies(Y_test).as_matrix(),y.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "y = wx + wx2 + wx3 + wx4 + wx5 + wx6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y.reset_index(inplace=True,drop=True)\n",
    "y.columns = mod.classes_\n",
    "y = y.merge(origtestdf[[\"Id\"]],how='left',left_index=True,right_index=True)\n",
    "y = y.fillna(0)\n",
    "y[\"Id\"] = y[\"Id\"].astype(int)\n",
    "y[\"Id\"] = y[\"Id\"].astype(str)\n",
    "\n",
    "for col in y.columns:\n",
    "    if col != \"Id\":\n",
    "        y[col] = y[col].round(decimals=6)\n",
    "        \n",
    "y.to_csv(\".\\\\Fifteenth_RF.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3315711801803829"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skm.log_loss(pd.get_dummies(Y_test).as_matrix(),x.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3753607677413036"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skm.log_loss(pd.get_dummies(Y_test).as_matrix(),x2.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skm.log_loss(pd.get_dummies(Y_test).as_matrix(),x3.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skm.log_loss(pd.get_dummies(Y_test).as_matrix(),x4.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skm.log_loss(pd.get_dummies(Y_test).as_matrix(),x5.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skm.log_loss(pd.get_dummies(Y_test).as_matrix(),x6.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   30.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    5.5s finished\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(\\\n",
    "origtraindf[[\"X_fit\",\"Y_fit\",\"Corner\"]],origtraindf[[\"Category\"]],\\\n",
    "        test_size = .2, random_state=19)\n",
    "mod4 = RandomForestClassifier(n_estimators=100,min_samples_leaf=25,max_depth=20\\\n",
    "                             ,n_jobs=-1,verbose=True,warm_start=True)\n",
    "mod4.fit(X_train,Y_train.as_matrix().ravel())\n",
    "x4 = pd.DataFrame(mod4.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   31.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    5.7s finished\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(\\\n",
    "origtraindf[[\"X_fit\",\"Y_fit\",\"hour\"]],origtraindf[[\"Category\"]],\\\n",
    "        test_size = .2, random_state=19)\n",
    "mod5 = RandomForestClassifier(n_estimators=100,min_samples_leaf=25,max_depth=20\\\n",
    "                             ,n_jobs=-1,verbose=True,warm_start=True)\n",
    "mod5.fit(X_train,Y_train.as_matrix().ravel())\n",
    "x5 = pd.DataFrame(mod5.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = pd.DataFrame(mod.predict_proba(origtestdf[\"\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4011392023905449"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skm.log_loss(pd.get_dummies(Y_test).as_matrix(),x3.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4046187323462394"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skm.log_loss(pd.get_dummies(Y_test).as_matrix(),x4.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   36.6s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   42.5s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    2.0s finished\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(\\\n",
    "origtraindf[[\"X_fit\",\"month\",\"hour\",\"year\"]],origtraindf[[\"Category\"]],\\\n",
    "        test_size = .2, random_state=19)\n",
    "mod6 = RandomForestClassifier(n_estimators=50,min_samples_leaf=25,max_depth=15\\\n",
    "                             ,n_jobs=-1,verbose=True,warm_start=True)\n",
    "mod6.fit(X_train,Y_train.as_matrix().ravel())\n",
    "x6 = pd.DataFrame(mod6.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4239100930434287"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skm.log_loss(pd.get_dummies(Y_test).as_matrix(),x5.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5326760113306572"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skm.log_loss(pd.get_dummies(Y_test).as_matrix(),x6.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   36.4s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   42.5s finished\n",
      "C:\\Users\\Kane.Merrill\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:267: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    1.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.4136487723959275"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod = RandomForestClassifier(n_estimators=50,min_samples_leaf=25,max_depth=15\\\n",
    "                             ,n_jobs=-1,verbose=True,warm_start=True)\n",
    "for i in range(4):\n",
    "    X_train_add,Y_train_add = resample(X_train,Y_train)\n",
    "    mod.fit(X_train_add,Y_train_add.as_matrix().ravel())\n",
    "x = mod.predict_proba(X_test)\n",
    "skm.log_loss(Y_test,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   36.1s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   41.9s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   36.8s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   42.5s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   36.3s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   42.2s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   36.5s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   42.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.3868404968595671"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod = RandomForestClassifier(n_estimators=50,min_samples_leaf=25,max_depth=15\\\n",
    "                             ,n_jobs=-1,verbose=True,warm_start=True)\n",
    "for i in range(4):\n",
    "    trees = 50 + (50*i)\n",
    "    mod.set_params(n_estimators=trees)\n",
    "    X_train_add,Y_train_add = resample(X_train,Y_train)\n",
    "    mod.fit(X_train_add,Y_train_add.as_matrix().ravel())\n",
    "x = mod.predict_proba(X_test)\n",
    "skm.log_loss(Y_test,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    8.3s finished\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    8.3s finished\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    8.4s finished\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    8.5s finished\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    8.4s finished\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    8.3s finished\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    8.3s finished\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    8.3s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   11.8s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:   14.4s finished\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (175610,39) (175610,38) (175610,39) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-6f1967a6fdcf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mX_train_add\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train_add\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m350000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mmod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_add\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train_add\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mskm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Kane.Merrill\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    552\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_proba\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 554\u001b[1;33m                 \u001b[0mproba\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mall_proba\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    555\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m             \u001b[0mproba\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (175610,39) (175610,38) (175610,39) "
     ]
    }
   ],
   "source": [
    "mod = RandomForestClassifier(min_samples_leaf=25,max_depth=15\\\n",
    "                             ,n_jobs=-1,verbose=True,warm_start=True)\n",
    "for i in range(8):\n",
    "    trees = 25 + (25*i)\n",
    "    mod.set_params(n_estimators=trees)\n",
    "    X_train_add,Y_train_add = StratifiedShuffleSplit(X_train,Y_train,n_samples=350000)\n",
    "    mod.fit(X_train_add,Y_train_add.as_matrix().ravel())\n",
    "x = mod.predict_proba(X_test)\n",
    "skm.log_loss(Y_test,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The least populated class in y has only 1 member, which is too few. The minimum number of labels for any class cannot be less than 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-fd3720538bd0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStratifiedShuffleSplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m.0001\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Kane.Merrill\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, y, n_iter, test_size, train_size, random_state)\u001b[0m\n\u001b[0;32m    960\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    961\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbincount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 962\u001b[1;33m             raise ValueError(\"The least populated class in y has only 1\"\n\u001b[0m\u001b[0;32m    963\u001b[0m                              \u001b[1;34m\" member, which is too few. The minimum\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m                              \u001b[1;34m\" number of labels for any class cannot\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The least populated class in y has only 1 member, which is too few. The minimum number of labels for any class cannot be less than 2."
     ]
    }
   ],
   "source": [
    "X = StratifiedShuffleSplit(X_train,test_size=.0001,random_state=3)\n",
    "for _,test in X:\n",
    "    print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "702439"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   36.4s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.4min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    4.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.3838382669871492"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod = RandomForestClassifier(n_estimators=100,min_samples_leaf=25,max_depth=15\\\n",
    "    ,n_jobs=-1,verbose=True,warm_start=True)\n",
    "mod.fit(X_train,Y_train.as_matrix().ravel())\n",
    "x = mod.predict_proba(X_test)\n",
    "skm.log_loss(Y_test,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    X_train_add,Y_train_add = resample(X_train,Y_train)\n",
    "    X_train = np.concatenate((X_train,X_train_add))\n",
    "    Y_train = np.concatenate((Y_train,Y_train_add))\n",
    "mod = RandomForestClassifier(n_estimators=50,min_samples_leaf=25,max_depth=15,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1      978092.6246            2.98m\n",
      "         2      964407.4593            2.79m\n",
      "         3      959784.2409            2.67m\n",
      "         4      957172.9023            2.56m\n",
      "         5      954168.3498            2.48m\n",
      "         6      950979.3228            2.40m\n",
      "         7      949123.6875            2.33m\n",
      "         8      947979.6759            2.26m\n",
      "         9      946750.1123            2.19m\n",
      "        10      946029.3889            2.11m\n",
      "        20      938194.8992            1.39m\n",
      "        30      933529.2112           41.35s\n",
      "        40      929994.3069            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.3262297762529183"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(\\\n",
    "origtraindf[[\"X_fit\",\"Y_fit\",\"year\",\"month\",\"hour\",\"PD_factor\"]],origtraindf[[\"New_Cat\"]],\\\n",
    "        test_size = .2, random_state=19)\n",
    "mod = GradientBoostingClassifier(n_estimators=40,learning_rate=.7,\\\n",
    "                                 min_samples_leaf=25,max_depth=3,verbose=1)\n",
    "mod.fit(X_train,Y_train.ravel())\n",
    "x = mod.predict_proba(X_test)\n",
    "skm.log_loss(Y_test,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3837611035727582"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(\\\n",
    "origtraindf[[\"X_fit\",\"Y_fit\",\"year\",\"month\",\"hour\",\"PD_factor\"]],origtraindf[[\"Category\"]],\\\n",
    "                                                    test_size = .2, random_state=19)\n",
    "mod = RandomForestClassifier(n_estimators=100,min_samples_leaf=25,max_depth=15,n_jobs=-1)\n",
    "mod.fit(X_train,Y_train.ravel())\n",
    "x = mod.predict_proba(X_test)\n",
    "skm.log_loss(Y_test,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.06981988,  0.12556554,  0.19709628,  0.2474611 ,  0.06906078,\n",
       "        0.03681681,  0.0844196 ,  0.10704838,  0.06271163])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   36.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.4min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    4.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.3452532382772509"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(\\\n",
    "origtraindf[[\"Corner\",\"Address_factor\",\"X_fit\",\"Y_fit\",\"rad\",\"DOW\",\"year\",\\\n",
    "\"hour\",\"PD_factor\"]],\\\n",
    "origtraindf[[\"Category\"]],test_size = .2, random_state=19)\n",
    "\n",
    "mod = RandomForestClassifier(n_estimators=100,min_samples_leaf=25,max_depth=15\\\n",
    "                             ,n_jobs=-1,verbose=True)\n",
    "\n",
    "mod.fit(X_train,Y_train.as_matrix().ravel())\n",
    "x = mod.predict_proba(X_test)\n",
    "skm.log_loss(Y_test,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3814574630399585"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(\\\n",
    "    origtraindf[[\"X_fit\",\"Y_fit\",\"rad\",\"DOW\",\"year\",\"week\",\"month\",\"hour\",\"PD_factor\"]],\\\n",
    "    origtraindf[[\"Category\"]],test_size = .2, random_state=19)\n",
    "mod = RandomForestClassifier(n_estimators=100,min_samples_leaf=25,max_depth=15\\\n",
    "                             ,n_jobs=-1,class_weight={'LARCENY/THEFT':.75})\n",
    "mod.fit(X_train,Y_train.as_matrix().ravel())\n",
    "x = mod.predict_proba(X_test)\n",
    "skm.log_loss(Y_test,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0725765 ,  0.11487591,  0.16964113,  0.22285616,  0.07273628,\n",
       "        0.02763808,  0.07120072,  0.03180305,  0.02316373,  0.03414093,\n",
       "        0.09195614,  0.06741137])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "act = pd.DataFrame(Y_test)\n",
    "act = pd.get_dummies(act[0])\n",
    "pred = pd.DataFrame(x,columns=act.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ASSAULT', 0.28524562792597624),\n",
       " ('NON-CRIMINAL', 0.31867741575960212),\n",
       " ('OTHER OFFENSES', 0.39237743958892879),\n",
       " ('LARCENY/THEFT', 0.43953792109229567),\n",
       " ('NON TOP FOUR', 0.66121315832486383)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic = {}\n",
    "lss = 0\n",
    "for col in act.columns:\n",
    "    loss = skm.log_loss(act[col],pred[col].as_matrix())\n",
    "    dic[col] = loss\n",
    "    lss = lss+loss\n",
    "    \n",
    "sorted_dic = sorted(dic.items(), key=operator.itemgetter(1))\n",
    "sorted_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l = \"HA/HA\"\n",
    "b = re.search(\"k\",l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mod = RandomForestClassifier(n_estimators=105,min_samples_leaf=25,max_depth=15,n_jobs=-1)\n",
    "mod.fit(origtraindf[[\"Corner\",\"Address_factor\",\"X_fit\",\"Y_fit\",\"rad\",\"DOW\",\"year\",\\\n",
    "\"hour\",\"PD_factor\"]],\\\n",
    "        origtraindf[[\"Category\"]].as_matrix().ravel())\n",
    "x = mod.predict_proba(origtestdf[[\"Corner\",\"Address_factor\",\"X_fit\",\"Y_fit\",\"rad\",\"DOW\",\"year\",\\\n",
    "\"hour\",\"PD_factor\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=15, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=25, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod = RandomForestClassifier(n_estimators=200,min_samples_leaf=25,max_depth=15,n_jobs=-1)\n",
    "mod.fit(origtraindf[[\"Corner\",\"Address_factor\",\"X_fit\",\"Y_fit\",\"rad\",\"DOW\",\"year\",\\\n",
    "\"hour\",\"PD_factor\"]],\\\n",
    "        origtraindf[[\"Category\"]].as_matrix().ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.44557595252991\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "tester = pd.DataFrame()\n",
    "rounds = np.ceil(((origtestdf.index.max()+1)/25000))\n",
    "for i in range(int(rounds)):\n",
    "    minn = i * 25000\n",
    "    maxx = 25000 + minn\n",
    "    x = pd.DataFrame(mod.predict_proba(origtestdf[[\"Corner\",\"Address_factor\",\"X_fit\"\\\n",
    "        ,\"Y_fit\",\"rad\",\"DOW\",\"year\",\"hour\",\"PD_factor\"]].loc[(\\\n",
    "                    origtestdf.index>=minn) & (origtestdf.index<maxx)]))\n",
    "    tester = tester.append(x)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tester.reset_index(inplace=True,drop=True)\n",
    "tester.columns = mod.classes_\n",
    "tester = tester.merge(origtestdf[[\"Id\"]],how='left',left_index=True,right_index=True)\n",
    "tester = tester.fillna(0)\n",
    "tester[\"Id\"] = tester[\"Id\"].astype(int)\n",
    "tester[\"Id\"] = tester[\"Id\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col in tester.columns:\n",
    "    if col != \"Id\":\n",
    "        tester[col] = tester[col].round(decimals=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tester.to_csv(\".\\\\Thirteenth_RF.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del x[\"NON TOP FOUR\"],x[\"Id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prev_data_to_add = pd.read_csv(\".\\Fourth_RF.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del prev_data_to_add[\"LARCENY/THEFT\"],prev_data_to_add[\"ASSAULT\"],prev_data_to_add[\"NON-CRIMINAL\"],prev_data_to_add[\"OTHER OFFENSES\"],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prev_data_to_add = prev_data_to_add.merge(x,left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prev_data_to_add.to_csv(\".\\Top_Four_Isolated_First.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
